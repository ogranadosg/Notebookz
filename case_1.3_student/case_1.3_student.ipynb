{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>How have global energy production trends changed over time?</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Goals</h2>\n",
    "<p>By the end of this case, you should be very comfortable writing your own functions using <code>pandas</code> and applying them to entire datasets. You'll understand how functions work in Python, including anonymous functions (using the keyword <code>lambda</code>), and you'll feel comfortable analyzing and manipulating larger datasets. You'll also have gained experience with exploring a dataset that is only loosely organised and about which you have very little initial information.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Introduction</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><strong>Business Context.</strong> Global electricity production, consumption, import, and export is complex and interesting for a variety of reasons. Each country has to keep track of a vast array of information to ensure that they produce enough electricity, yet balance these needs against medium-term financial implications and environmental concerns.</p>\n",
    "<p>You are an analyst working at a non-governmental organization (NGO) that reports on global energy trends. Your department has acquired a large CSV file, but your colleagues are battling to extract relevant insights from it using Excel due to its size and format. Worse still, it has thousands of variables and they are not sure which ones are interesting. Thus, you have been made responsible for supporting your team's journalists by providing them with data and insights that they can turn into written reports.</p>\n",
    "<p><strong>Business Problem.</strong>  Your task is to <strong>break the available data down into smaller files, understand the information that is available, and extract key insights for an upcoming report on global power patterns.</strong> Specifically, your team wants you to answer the following questions:</p>\n",
    "<ul>\n",
    "<li>How much power is produced?</li>\n",
    "<li>How much power is consumed?</li>\n",
    "<li>How much power is imported and exported? </li>\n",
    "<li>How much of this power is renewable?</li>\n",
    "<li>How are these trends in production, consumption, import, and export changing over time?</li>\n",
    "</ul>\n",
    "<p><strong>Analytical Context.</strong> The data is stored in a large CSV file containing information on power production and consumption by country and year. You will: 1) break down the data into summarized CSV files to share with your colleagues; 2) manipulate the data to create more categories from the existing columns; 3) find the biggest players in different categories, including total energy export and total production by type (e.g. nuclear); and finally 4) find trends in the data, such as which countries have the fastest growing energy production.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Getting started with the International Energy Statistics data</h2>\n",
    "<p>The data file you have been given is a single CSV located at <code>data/all_energy_statistics.csv</code>. Your colleagues have informed you that the data is from http://data.un.org/Explorer.aspx, but they don't know much else about it. </p>\n",
    "<p>They specifically note that the data is very [\"narrow\"] (https://en.wikipedia.org/wiki/Wide_and_narrow_data). Although the file contains data for a wide variety of things, such as \"Total Energy Production\" all the way through to \"Additives and Oxygenates - Exports\", it has very few columns. </p>\n",
    "<p>Generally, when dealing with \"wide\" data, we can be fairly sure that all data in the same column is comparable. In this case, you'll notice a <code>unit</code> column. Not all numerical data in the <code>quantity</code> column is directly comparable. For example, sometimes the number in this column is defined in terms of \"Metric tons, thousand\" and sometimes in \"Kilowatt-hours, million\" -- evidently very different concepts!</p>\n",
    "<p>As always, our first step is to read the data from disk and take a look at the first few rows:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"all_energy_statistics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>You'll notice that there is more of a delay than before when running the <code>read_csv</code> function. This dataset has over 1 million rows, so it takes a while to load it all into memory. From the first rows, we can immediately gain some useful insights</p>\n",
    "<ul>\n",
    "<li>The <code>category</code> column looks like it is well organized. All the samples we see are lowercase and underscores are used instead of spaces</li>\n",
    "<li>The <code>commodity_transaction</code> column looks more like a human-readable description. We can see how it includes a description of the category (e.g. \"additives_and_oxygenates\" matches with \"Additives and Oxygenates\" and \"wind_electricity\" matches with \"Electricity - ....wind....\")</li>\n",
    "<li>We see <code>year</code> ranges from at least 1995 to 2014 </li>\n",
    "<li>As mentioned before, we'll need to be careful when comparing quantities, as the <code>unit</code> column might change the meaning of the <code>quantity</code> column.</li>\n",
    "</ul>\n",
    "<p>A good first question to ask is how many unique values there are for the following columns:</p>\n",
    "<ul>\n",
    "<li><code>country_or_area</code></li>\n",
    "<li><code>commodity_transaction</code></li>\n",
    "<li><code>year</code></li>\n",
    "<li><code>category</code></li>\n",
    "</ul>\n",
    "<p>Let's find out:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.year.min())\n",
    "print(df.year.max())\n",
    "print(\"----------\")\n",
    "print(\"commodity_transaction\")\n",
    "print(df.commodity_transaction.unique())\n",
    "print()\n",
    "print(\"num unique values: \", len(df.commodity_transaction.unique()))\n",
    "print()\n",
    "print(\"----------\")\n",
    "print(df.category.unique())\n",
    "print()\n",
    "print(\"num unique values: \", len(df.category.unique()))\n",
    "print()\n",
    "print(\"---------------\")\n",
    "print(df.country_or_area.unique())\n",
    "print()\n",
    "print(\"num unique values: \", len(df.country_or_area.unique()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We can see that <code>country_or_area</code> has 243 unique values, more than the officially recognised 195, because this list includes some former countries such as the USSR as well as areas like Antarctic Fisheries which are not formal countries.</p>\n",
    "<p>As expected, the <code>categories</code> column is well standardized and breaks each row into one of 71 unique categories, while the <code>commodity_transaction</code> row is slightly more chaotic and consists of 2452 unique values.</p>\n",
    "<p>In terms of time, our data ranges from 1990 - 2014 inclusive, so 25 years in total.</p>\n",
    "<p>Note that the output of <code>unique()</code> is automatically truncated for large lists, with a <code>...</code> inserted to indicate this.</p>\n",
    "<p>Since the <code>commodity_transaction</code> column is a bit chaotic, we'll need to touch it up a bit. Let's create a copy of our dataframe before we start changing it so we can refer back to the original values if necessary.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The first thing we noticed about the <code>commodity_transaction</code> column is that it uses hyphens (<code>-</code>) as separators. We can also see that it uses lowercase and capital letters - often something that makes analysis harder if we are going to do any string matching (e.g. find the word \"production\", which might skip descriptions which use \"Production\" instead). </p>\n",
    "<p>Let's start by lowercasing all of the descriptions. In the previous case, you learned how to do this by creating a separate list, looping through the dataframe, and then adding all the items from the list as a new column. We could achieve what we wanted as follows:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clean_transaction_list = []\n",
    "\n",
    "for item in df['commodity_transaction']:\n",
    "    item = item.lower()\n",
    "    clean_transaction_list.append(item)\n",
    "    \n",
    "df['clean_transaction'] = clean_transaction_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We added <code>%%time</code> at the top of our cell to make Jupyter output information about how long it took to run that cell. We can see that looping through our DataFrame and adding the column took nearly 1 second to complete. It also took 5 lines of code.</p>\n",
    "<p>As its very common to need to apply the same operation on every row of a dataset, <code>pandas</code> provides a shortcut to do this. You can use the <code>.apply()</code> function on a DataFrame directly and pass in a function to apply to every row. This is more efficient in two ways:</p>\n",
    "<ul>\n",
    "<li>It takes fewer lines of code, so it's faster to write the code (and to read it)</li>\n",
    "<li><code>apply()</code> is optimized to take advantage of modern CPU features such as vectorization, so it runs in less time</li>\n",
    "</ul>\n",
    "<p>We can achieve exactly the same result as we did with our <code>for</code> loop using the <code>apply()</code> function as follows:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['clean_transaction2'] = df['commodity_transaction'].apply(str.lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Here we can see that <code>.apply()</code> ran around twice as quickly as the iterative version and produced the same results (the <code>clean_transaction</code> and <code>clean_transaction2</code> columns are the same). You can read more about the <code>apply()</code> function <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.apply.html\">here</a>, but in essence you call it from a column of a DataFrame and pass in a function. It applies that function to every row of that column in the DataFrame. In this case, we passed in the <code>str.lower</code> function, which converts a string to lowercase.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Pre-processing and pivoting our data</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We noted before that the <code>commodity_transaction</code> column seemed to use hyphens to separate different concepts in a single column. Let's do some more analysis to see if this is true across the board.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Exercise 1:</h3>\n",
    "<p>Find out how many of the 2,000+ unique columns contain:</p>\n",
    "<ul>\n",
    "<li>0 hyphens</li>\n",
    "<li>exactly 1 hyphen</li>\n",
    "<li>more than 1 hyphen</li>\n",
    "</ul>\n",
    "<p><strong>Hint:</strong> You can use Python's built-in <a href=\"https://www.w3schools.com/python/ref_string_count.asp\"><code>count()</code></a> method to count the occurrences of a character in a string).</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ans_st"
    ]
   },
   "source": [
    "**Answer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Exercise 2:</h3>\n",
    "<p>Write code to print out all descriptions with zero hyphens. What do you notice about these?</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ans_st"
    ]
   },
   "source": [
    "**Answer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Passing our own functions to <code>apply()</code></h3>\n",
    "<p>We previously passed the built-in <code>str.lower()</code> function to the <code>apply()</code> function to apply to it every row in our DataFrame. Now we want to clean up the m-dashes and lowercase the result at the same time. Let's write our own custom Python function to do both, and pass that to <code>apply()</code> instead. You can read more about writing your own custom functions in Python <a href=\"https://www.w3schools.com/python/python_functions.asp\">here</a>:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_transaction_description(transaction_description):\n",
    "    \"\"\"Lowercase the input and replace all m-dashes with hyphens\"\"\"\n",
    "    clean = transaction_description.lower()\n",
    "    clean = clean.replace(\"–\", \"-\")\n",
    "    return clean\n",
    "    \n",
    "\n",
    "# drop the columns we added before so we can recreate them with our new clean function\n",
    "df = df.drop(columns=['clean_transaction', 'clean_transaction2'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_transaction'] = df['commodity_transaction'].apply(clean_transaction_description)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Here we used <code>apply()</code> again, but this time passed in our own function which did both the lowercasing and the replacing of m-dashes with hyphens.</p>\n",
    "<p>We've now seen how to use the <code>apply()</code> function with both built-in functions and our own custom functions. There's one more way we can use <code>apply()</code> though: with custom <strong>anonymous functions</strong> using the Python <code>lambda</code> keyword. Let's see how to achieve the same result using <code>lambda</code>:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['clean_transaction'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowercase the description and replace m-dashes with hyphens in one line\n",
    "df['clean_transaction'] = df['commodity_transaction'].apply(lambda x: x.lower().replace(\"–\", \"-\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>This code is functionally equivalent to what we ran before, but it's more concise. Instead of giving our function a name (<code>clean_transaction_description</code>), we can declare an anonymous function by using the <a href=\"https://www.w3schools.com/python/python_lambda.asp\"><code>lambda</code></a> keyword. This says that we are going to pass in a series of <code>x</code> values (the descriptions), and describes what to do to each of them. The advantage of doing this is that it's more concise. The disadvantage is that it can be harder to read and it prevents us from using our function again later without redefining it all over again.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Extracting the most interesting rows</h3>\n",
    "<p>It's hard to manually inspect over 2,000 unique description values, but we know that we're mainly interested in: </p>\n",
    "<ul>\n",
    "<li>Import</li>\n",
    "<li>Export</li>\n",
    "<li>Total production</li>\n",
    "<li>Total demand or consumption</li>\n",
    "<li>Renewables</li>\n",
    "</ul>\n",
    "<p>We can search for some keywords in the descriptions using code similar to the following:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in df['clean_transaction'].unique() if \"import\" in x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>This gives us a much more manageable list to look through, and we can see that \"electricity - imports\" is likely an interesting value. We can cross-check this in the main dataset (and see all columns to boot) as follows:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note the below is functionally equivalent to \n",
    "# df[df[\"clean_transaction\"] == \"electricity - imports\"].head()\n",
    "# but slightly easier to type\n",
    "\n",
    "df[df.clean_transaction == \"electricity - imports\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Exercise 3:</h3>\n",
    "<p>Use the above method or any other method that you prefer to explore the transaction descriptions and define a Python list containing the 9 most interesting ones. These should cover the total values for import, export, total production, total demand, and renewable energy production.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ans_st"
    ]
   },
   "source": [
    "**Answer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Pivoting the interesting values into their own columns</h3>\n",
    "<p>Of course, now that we've identified the most interesting transaction descriptions, we probably ought to pull them out of that single column that they're stuck in. Let's \"pivot\" our data to a more useable format, keeping each of these interesting values as new columns. This translates our data from a fairly narrow format into a wider one.</p>\n",
    "<p>You might know of \"pivot tables\" from Excel. If not, don't worry - you'll come across them later and in more detail. But if you do know of them, you'll recognize that this pretty much the exact same thing. We'll use the pivot function in pandas, which you can read more about <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.pivot.html\">here</a>. For now, just try to understand how the following code works, but you won't be expected to do this yourself until you've gained more experience with <code>pandas</code>:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll keep our \"interesting\" values after we turn them into columsn\n",
    "# but we'll also keep the \"country\" and \"year\" columns\n",
    "final_keep_values = [\"country_or_area\", \"year\"] + keep_values\n",
    "\n",
    "# Turn values in the 'commodity transaction' column\n",
    "# into our new column names\n",
    "# and keep only the 'quantity' column as the new values\n",
    "df_countries = pd.pivot_table(\n",
    "    df,\n",
    "    values=\"quantity\",\n",
    "    index=[\"country_or_area\", \"year\"],\n",
    "    columns=\"commodity_transaction\",\n",
    ").reset_index()[final_keep_values]\n",
    "\n",
    "# rename the columns to be more concise\n",
    "df_countries.columns = [\n",
    "    \"country\",\n",
    "    \"year\",\n",
    "    \"demand\",\n",
    "    \"production\",\n",
    "    \"imports\",\n",
    "    \"exports\",\n",
    "    \"hydro\",\n",
    "    \"wind\",\n",
    "    \"solar\",\n",
    "    \"geothermal\",\n",
    "    \"tide\",\n",
    "]\n",
    "\n",
    "# output with the energy production leaders first\n",
    "df_countries.sort_values(by=\"production\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We can see thaht our data is in a much more user-friendly format now. We have kept only the quantity column and each row now represents one country in a particular year. If we had data for each year for each of the 243 countries or areas, we would expect to have 6075 rows, but we have only 5568. This makes sense as some countries stopped existing and data collection in general has become much easier and more consistent over time. Let's take a look at how many countries we have data on for each year:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_countries['year'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>As expected, in earlier years, we have data for fewer countries.</p>\n",
    "<p>The final check we should do is whether any of the values we kept used a different \"unit\". A quick scan of the data shows that all of the values we are interested in are measured in \"Kilowatt-hours, million\", but it's possible that some small values could be measured as \"Kilowatt-hours, thousand\", for example. Let's look for unique values used in our <code>keep_values</code> list:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = keep_values[0]\n",
    "all_units = []\n",
    "\n",
    "for value in keep_values:\n",
    "    units_used = list(df[df.commodity_transaction == value]['unit'].unique())\n",
    "    all_units += units_used\n",
    "print(set(all_units))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>All good! Only one unit is used. So we are done with data preparation and we can start exploring our dataset for information.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Exploring growth of power production and renewables</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>As mentioned, the team is interested in analyzing countries based on their renewable energy production. We currently know how much power they produce in total and how much of this is due to each of a number of renewable options. We'll start by adding some supplementary data and then analyzing our dataset for interesting countries and patterns.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Exercise 4:</h3>\n",
    "<p>Add a new summary column called <code>renewable_percent</code> which gives the percentage of total power production which is made up of renewable energy.</p>\n",
    "<p><strong>Hint:</strong> You might notice that some values are <code>na</code>, meaning <code>not available</code>. We can probably assume that these are 0 (though this might not always be meaningful; e.g. if we don't have data on the USSR in 2014, it's not because its power plants are all turned off!). You can use the <code>pandas</code> <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html\"><code>fillna</code></a> method to replace <code>na</code> values with 0.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ans_st"
    ]
   },
   "source": [
    "**Answer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Exercise 5:</h3>\n",
    "<p>Considering only the most recent year that we have data for (2014), which 5 countries produced the largest proportion of their power through renewables, and which 5 countries produced the smallest proportion of their power through renewables?</p>\n",
    "<p><strong>Hint:</strong> You can use the <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sort_values.html\"><code>sort_values</code></a> method in <code>pandas</code> to sort a DataFrame by a specific column, either descending or ascending.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ans_st"
    ]
   },
   "source": [
    "**Answer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Question:</h3>\n",
    "<p>Why do you think we are seeing a lot of very small countries on both lists?</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Very small countries are not particularly representative of the global renewable power situation, so your team asks you to restrict your analysis only to countries that produce a lot of power.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Exercise 6:</h3>\n",
    "<p>Repeat the above analysis but only look at the countries in the top 10% of total power production.</p>\n",
    "<p><strong>Hint:</strong> You can filter a DataFrame with multiple conditions by using the <code>&amp;</code> symbol; e.g.:</p>\n",
    "<p><code>df_countries[df_countries.year == 2014 &amp; df_countries.wind &gt; 0]</code> </p>\n",
    "<p>would give you a DataFrame of all countries in 2014 which had produced at least some wind power.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ans_st"
    ]
   },
   "source": [
    "**Answer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Of course, your team is also interested in looking at change in renewable energy over time. Let's look at the top and bottom 5 countries where the percentage of renewable energy they produced in 2014 is <strong>very different</strong> from the percentage in 1990.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Exercise 7:</h3>\n",
    "<p>Add a new column to your DataFrame which displays the difference in percentage renewable energy production between 2014 and 1990. Which are the top and bottom 5 countries? What do you notice about these countries? Perform this analysis both with all countries and again with only those in the 10% of total power production.</p>\n",
    "<p><strong>Hint:</strong> you can use the <code>pivot()</code> method again to create a DataFrame which has 1990 and 2014 as columns and <code>renewable_percent</code> as values to help with this by using the following code</p>\n",
    "<p><code>renewable_change = pd.pivot_table(\n",
    "    df_countries, values=\"renewable_percent\", index=[\"country\"], columns=\"year\",\n",
    ").reset_index()[[\"country\", 1990, 2014]]</code></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ans_st"
    ]
   },
   "source": [
    "**Answer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Exercise 8:</h3>\n",
    "<p>Your team is also interested in countries which are producing a lot more power now than they were 25 years ago. What are the top and bottom 10 countries in terms of growth of:</p>\n",
    "<ul>\n",
    "<li>Total power</li>\n",
    "<li>Renewable power</li>\n",
    "</ul>\n",
    "<p>Note that because many countries were producing zero or very little renewable energy in 1990, doing a basic growth calculation will show that many countries have \"infinite\" (represented as <code>inf</code> in <code>pandas</code>) growth. To avoid this, restrict your results to countries which produced at least 1,000 units of renewable power in 1990 for the renewable growth analysis and at least 1,000 units of total power for the total growth analysis.</p>\n",
    "<p><strong>Hint:</strong> Assuming you add a column called <code>renewable_total</code>, you can use the following pivots to generate tables similar to before for both renewable growth and total growth:</p>\n",
    "<p><code>renewable_growth = pd.pivot_table(\n",
    "    df_countries, values=\"renewable_total\", index=[\"country\"], columns=\"year\",\n",
    ").reset_index()[[\"country\", 1990, 2014]]</code></p>\n",
    "<p><code>total_growth = pd.pivot_table(\n",
    "    df_countries, values=\"production\", index=[\"country\"], columns=\"year\",\n",
    ").reset_index()[[\"country\", 1990, 2014]]</code></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ans_st"
    ]
   },
   "source": [
    "**Answer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Exercise 9:</h3>\n",
    "<p>Finally, your team wants an easy-to-read label for each country based on total growth. They have given you the following specification for how the countries should be labeled:</p>\n",
    "<ul>\n",
    "<li>zero or negative growth = \"No growth\"</li>\n",
    "<li>1% -100% growth = \"Growing\"</li>\n",
    "<li>over 100% growth = \"Growing fast\"</li>\n",
    "<li>NaN (if the data from 1990 or 2014 is NaN) = \"Not Applicable\"</li>\n",
    "</ul>\n",
    "<p>Calculate the label for each country, using the <code>apply()</code> method for efficiency. </p>\n",
    "<p><strong>Hint:</strong> You can check if the value of variable <code>x</code> is Nan as follows:</p>\n",
    "<p><code>import numpy as np\n",
    "np.isnan(x)</code></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ans_st"
    ]
   },
   "source": [
    "**Answer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Largest importers and exporters of energy</h2>\n",
    "<p>The final thing that your team wants to look into is imports and exports of energy by country.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Exercise 10:</h3>\n",
    "<p>Your team wants to know:</p>\n",
    "<ul>\n",
    "<li>Which countries have imported and exported the most power in total</li>\n",
    "<li>Which countries have imported the largest percentage of their <em>demand</em> and exported the largest percentage of their <em>production</em></li>\n",
    "</ul>\n",
    "<p>Do the analysis for all countries <em>and</em> for only countries with total production in the top 10%.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ans_st"
    ]
   },
   "source": [
    "**Answer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Writing new country-specific summary data to disk</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Your team is delighted that you've managed to make sense of the data and extract some insights. They want to explore the data themselves too, but all of their existing tools are designed to analyze data from only one country at a time. They have asked that you create separate CSV files for each country, using the country as the file name, with a maximum of 25 rows per file (one per year) and columns for imports, exports, etc.</p>\n",
    "<p>To do this, we use the <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html\"><code>to_csv</code></a> function on a given DataFrame to write it to a file. We create a new directory called \"output_csvs\" in our working directory so that we don't clutter up our workspace with 243 CSV files. Then we run the following code to write our data to disk:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIRECTORY = \"output_csvs\"\n",
    "\n",
    "if not os.path.exists(OUTPUT_DIRECTORY):\n",
    "    os.makedirs(OUTPUT_DIRECTORY)\n",
    "\n",
    "for country in df_countries['country'].unique():\n",
    "    country_df = df_countries[df_countries.country == country].drop(columns='country')\n",
    "    country_df.to_csv(f\"{OUTPUT_DIRECTORY}/{country}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Conclusions</h2>\n",
    "<p>We saw a number of interesting trends in the global energy industry. Specifically, we saw that many countries are relying more and more on renewables, but that some of the countries with fast-growing demand are forced to turn to non-renewable sources to keep up.</p>\n",
    "<p>We also noticed that contrary to our expectations of some countries being \"net importers\" and others being \"net exporters\" of power, many countries actually both import <em>and</em> export large amounts of power.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Takeaways</h2>\n",
    "<p>In this case, we covered some more features of <code>pandas</code> and got more practice with the features we covered previously. Specifically we saw how to:</p>\n",
    "<ul>\n",
    "<li>Use the <code>apply()</code> method in <code>pandas</code> with build-in functions, custom functions, and anonymous functions</li>\n",
    "<li>Work with large datasets and explore these using basic string matching to find interesting columns, and reformat the results into more convenient formats</li>\n",
    "<li>Pivot between wide and narrow formats</li>\n",
    "<li>Plot basic line plots</li>\n",
    "<li>Break up a large dataset into smaller ones and write these back to disk</li>\n",
    "</ul>\n",
    "<p>While you'll learn more advanced functionality than this in later cases, these basics will be used again and again, so keep coming back to this case as reference material as often as you need.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
